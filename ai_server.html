<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Server Hardware Requirements Calculator</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background: linear-gradient(135deg, #0a0e27 0%, #1a1a2e 25%, #16213e 50%, #0f3460 100%);
            min-height: 100vh;
            padding: 20px;
            position: relative;
        }

        body::before {
            content: '';
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: radial-gradient(circle at 20% 80%, rgba(34, 197, 94, 0.1) 0%, transparent 50%),
                        radial-gradient(circle at 80% 20%, rgba(168, 85, 247, 0.08) 0%, transparent 50%),
                        radial-gradient(circle at 40% 40%, rgba(59, 130, 246, 0.06) 0%, transparent 50%);
            pointer-events: none;
            z-index: -1;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
            background: rgba(255, 255, 255, 0.02);
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 24px;
            box-shadow: 0 32px 64px rgba(0, 0, 0, 0.4);
            backdrop-filter: blur(20px);
            overflow: hidden;
            animation: slideUp 0.8s ease-out;
        }

        @keyframes slideUp {
            from {
                opacity: 0;
                transform: translateY(50px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .header {
            background: linear-gradient(135deg, #1e293b 0%, #0f172a 100%);
            color: #e2e8f0;
            padding: 40px;
            text-align: center;
            position: relative;
            overflow: hidden;
        }

        .header::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: linear-gradient(135deg, rgba(34, 197, 94, 0.1) 0%, rgba(168, 85, 247, 0.05) 100%);
            z-index: 1;
        }

        .header * {
            position: relative;
            z-index: 2;
        }

        .header h1 {
            font-size: 3rem;
            font-weight: 800;
            margin-bottom: 12px;
            background: linear-gradient(135deg, #22c55e 0%, #a855f7 50%, #3b82f6 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            letter-spacing: -0.02em;
        }

        .header p {
            font-size: 1.2rem;
            opacity: 0.8;
            font-weight: 400;
            color: #94a3b8;
        }

        .info-section {
            background: linear-gradient(135deg, rgba(30, 41, 59, 0.9) 0%, rgba(51, 65, 85, 0.8) 100%);
            padding: 40px 50px;
            border-bottom: 1px solid rgba(255, 255, 255, 0.1);
            color: #cbd5e1;
        }

        .info-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 30px;
            margin-top: 30px;
        }

        .info-card {
            background: rgba(15, 23, 42, 0.6);
            border-radius: 16px;
            padding: 25px;
            border: 1px solid rgba(34, 197, 94, 0.2);
            transition: all 0.3s ease;
        }

        .info-card:hover {
            transform: translateY(-5px);
            border-color: rgba(34, 197, 94, 0.4);
            box-shadow: 0 15px 30px rgba(0, 0, 0, 0.2);
        }

        .info-card h3 {
            color: #22c55e;
            font-size: 1.2rem;
            font-weight: 700;
            margin-bottom: 12px;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .info-card p {
            font-size: 0.95rem;
            line-height: 1.6;
            color: #94a3b8;
        }

        .section-title {
            font-size: 1.8rem;
            font-weight: 700;
            color: #e2e8f0;
            margin-bottom: 15px;
            text-align: center;
        }

        .section-subtitle {
            text-align: center;
            color: #94a3b8;
            font-size: 1.1rem;
            margin-bottom: 20px;
        }

        .main-content {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 0;
            min-height: 600px;
        }

        .input-section {
            padding: 50px;
            background: linear-gradient(135deg, rgba(15, 23, 42, 0.9) 0%, rgba(30, 41, 59, 0.8) 100%);
            border-right: 1px solid rgba(255, 255, 255, 0.1);
        }

        .results-section {
            padding: 50px;
            background: linear-gradient(135deg, rgba(2, 6, 23, 0.95) 0%, rgba(15, 23, 42, 0.9) 100%);
            color: #e2e8f0;
            position: relative;
        }

        .results-section::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: radial-gradient(circle at 70% 30%, rgba(34, 197, 94, 0.1) 0%, transparent 60%);
            pointer-events: none;
        }

        .form-group {
            margin-bottom: 25px;
            animation: fadeInLeft 0.6s ease-out;
            animation-fill-mode: both;
        }

        .form-group:nth-child(1) { animation-delay: 0.1s; }
        .form-group:nth-child(2) { animation-delay: 0.2s; }
        .form-group:nth-child(3) { animation-delay: 0.3s; }
        .form-group:nth-child(4) { animation-delay: 0.4s; }
        .form-group:nth-child(5) { animation-delay: 0.5s; }
        .form-group:nth-child(6) { animation-delay: 0.6s; }
        .form-group:nth-child(7) { animation-delay: 0.7s; }
        .form-group:nth-child(8) { animation-delay: 0.8s; }

        @keyframes fadeInLeft {
            from {
                opacity: 0;
                transform: translateX(-30px);
            }
            to {
                opacity: 1;
                transform: translateX(0);
            }
        }

        label {
            display: block;
            margin-bottom: 10px;
            font-weight: 600;
            color: #cbd5e1;
            font-size: 0.95rem;
            letter-spacing: 0.025em;
        }

        input, select {
            width: 100%;
            padding: 16px 20px;
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 16px;
            font-size: 1rem;
            transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
            background: rgba(15, 23, 42, 0.5);
            color: #e2e8f0;
            backdrop-filter: blur(10px);
        }

        input::placeholder {
            color: #64748b;
        }

        input:focus, select:focus {
            outline: none;
            border-color: #22c55e;
            box-shadow: 0 0 0 4px rgba(34, 197, 94, 0.1), 0 8px 25px rgba(34, 197, 94, 0.15);
            transform: translateY(-2px);
            background: rgba(15, 23, 42, 0.8);
        }

        input:hover, select:hover {
            border-color: rgba(34, 197, 94, 0.5);
            background: rgba(15, 23, 42, 0.7);
        }

        select option {
            background: #1e293b;
            color: #e2e8f0;
            padding: 12px;
        }

        .calculate-btn {
            width: 100%;
            padding: 18px;
            background: linear-gradient(135deg, #22c55e 0%, #16a34a 100%);
            color: white;
            border: none;
            border-radius: 16px;
            font-size: 1.1rem;
            font-weight: 700;
            cursor: pointer;
            transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);
            margin-top: 30px;
            text-transform: uppercase;
            letter-spacing: 1.5px;
            position: relative;
            overflow: hidden;
        }

        .calculate-btn::before {
            content: '';
            position: absolute;
            top: 0;
            left: -100%;
            width: 100%;
            height: 100%;
            background: linear-gradient(90deg, transparent, rgba(255, 255, 255, 0.2), transparent);
            transition: left 0.5s;
        }

        .calculate-btn:hover::before {
            left: 100%;
        }

        .calculate-btn:hover {
            transform: translateY(-4px);
            box-shadow: 0 20px 40px rgba(34, 197, 94, 0.4);
            background: linear-gradient(135deg, #16a34a 0%, #15803d 100%);
        }

        .calculate-btn:active {
            transform: translateY(-2px);
        }

        .results-title {
            font-size: 2.2rem;
            font-weight: 800;
            margin-bottom: 40px;
            text-align: center;
            background: linear-gradient(135deg, #22c55e 0%, #a855f7 50%, #3b82f6 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            letter-spacing: -0.02em;
            position: relative;
            z-index: 2;
        }

        .result-card {
            background: rgba(15, 23, 42, 0.4);
            backdrop-filter: blur(20px);
            border-radius: 20px;
            padding: 30px;
            margin-bottom: 25px;
            border: 1px solid rgba(34, 197, 94, 0.2);
            transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);
            opacity: 0;
            transform: translateY(30px);
            position: relative;
            overflow: hidden;
        }

        .result-card::before {
            content: '';
            position: absolute;
            top: 0;
            left: -100%;
            width: 100%;
            height: 100%;
            background: linear-gradient(90deg, transparent, rgba(34, 197, 94, 0.1), transparent);
            transition: left 0.6s;
        }

        .result-card:hover::before {
            left: 100%;
        }

        .result-card.show {
            opacity: 1;
            transform: translateY(0);
        }

        .result-card:hover {
            transform: translateY(-8px);
            box-shadow: 0 25px 50px rgba(0, 0, 0, 0.3);
            border-color: rgba(34, 197, 94, 0.4);
        }

        .result-item {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 16px;
            padding: 12px 0;
            border-bottom: 1px solid rgba(34, 197, 94, 0.1);
            position: relative;
            z-index: 2;
        }

        .result-item:last-child {
            border-bottom: none;
            margin-bottom: 0;
        }

        .result-label {
            font-weight: 600;
            font-size: 1rem;
            color: #cbd5e1;
            letter-spacing: 0.025em;
        }

        .result-value {
            font-weight: 800;
            font-size: 1.2rem;
            text-align: right;
            color: #f8fafc;
        }

        .assumptions-section {
            margin-top: 30px;
            background: rgba(2, 6, 23, 0.6);
            border-radius: 20px;
            padding: 30px;
            opacity: 0;
            transform: translateY(30px);
            border: 1px solid rgba(168, 85, 247, 0.2);
            position: relative;
            overflow: hidden;
        }

        .assumptions-section::before {
            content: '';
            position: absolute;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: radial-gradient(circle at 30% 70%, rgba(168, 85, 247, 0.1) 0%, transparent 60%);
            pointer-events: none;
        }

        .assumptions-section.show {
            opacity: 1;
            transform: translateY(0);
        }

        .assumptions-title {
            font-size: 1.4rem;
            font-weight: 700;
            margin-bottom: 20px;
            text-align: center;
            color: #e2e8f0;
            position: relative;
            z-index: 2;
        }

        .loading {
            text-align: center;
            padding: 60px;
            font-size: 1.3rem;
            color: #94a3b8;
            position: relative;
            z-index: 2;
        }

        .spinner {
            width: 60px;
            height: 60px;
            border: 3px solid rgba(34, 197, 94, 0.1);
            border-top: 3px solid #22c55e;
            border-radius: 50%;
            animation: spin 1.2s linear infinite;
            margin: 0 auto 30px;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }

        .highlight-value {
            color: #22c55e;
            text-shadow: 0 0 15px rgba(34, 197, 94, 0.3);
            font-weight: 900;
        }

        .assumptions-info {
            background: linear-gradient(135deg, rgba(30, 41, 59, 0.9) 0%, rgba(51, 65, 85, 0.8) 100%);
            padding: 40px 50px;
            border-top: 1px solid rgba(255, 255, 255, 0.1);
            color: #cbd5e1;
        }

        .key-metrics {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin-top: 25px;
        }

        .metric-card {
            background: rgba(15, 23, 42, 0.4);
            border-radius: 12px;
            padding: 20px;
            border: 1px solid rgba(168, 85, 247, 0.2);
            text-align: center;
        }

        .metric-title {
            font-size: 0.9rem;
            color: #94a3b8;
            margin-bottom: 8px;
            font-weight: 600;
        }

        .metric-value {
            font-size: 1.1rem;
            color: #a855f7;
            font-weight: 700;
        }

        @media (max-width: 768px) {
            .main-content {
                grid-template-columns: 1fr;
            }
            
            .header h1 {
                font-size: 2.5rem;
            }
            
            .input-section, .results-section {
                padding: 30px;
            }

            .info-section, .assumptions-info {
                padding: 30px;
            }

            .info-grid {
                grid-template-columns: 1fr;
                gap: 20px;
            }

            .key-metrics {
                grid-template-columns: repeat(2, 1fr);
                gap: 15px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>🤖 AI Server Hardware Calculator</h1>
            <p>NVIDIA Triton-based inference server capacity planning for computer vision workloads</p>
        </div>

        <!-- Information Section -->
        <div class="info-section">
            <div class="section-title">🧠 Understanding AI Inference Parameters</div>
            <div class="section-subtitle">Learn how each parameter affects your AI server's computational requirements</div>
            
            <div class="info-grid">
                <div class="info-card">
                    <h3>📹 Video Streams</h3>
                    <p>Number of concurrent video streams being processed. Each stream requires dedicated GPU memory and compute resources. Enterprise AI systems typically handle 10-50 streams per GPU depending on model complexity.</p>
                </div>
                
                <div class="info-card">
                    <h3>🎯 Models per Stream</h3>
                    <p>AI models running simultaneously on each stream (object detection, classification, tracking, etc.). Multiple models require pipeline orchestration and can share GPU memory efficiently with batching.</p>
                </div>
                
                <div class="info-card">
                    <h3>🎬 Inference FPS</h3>
                    <p>Frames processed per second for AI inference. Higher FPS provides real-time analysis but exponentially increases compute requirements. Typical range: 4-30 FPS based on use case criticality.</p>
                </div>
                
                <div class="info-card">
                    <h3>📺 Input Resolution</h3>
                    <p>Video resolution for AI processing. Lower resolutions (320p-480p) are preferred for real-time inference as they reduce memory usage and increase throughput while maintaining reasonable accuracy.</p>
                </div>
                
                <div class="info-card">
                    <h3>🧠 Model Complexity</h3>
                    <p>Computational intensity of your AI models. Lightweight models (MobileNet, YOLOv5s) vs Heavy models (ResNet, YOLOv8x). Affects GPU memory, compute requirements, and batch sizes.</p>
                </div>
                
                <div class="info-card">
                    <h3>⚡ Batch Size</h3>
                    <p>Number of frames processed together. Larger batches improve GPU utilization and throughput but increase latency and memory usage. Optimal batching balances performance with real-time requirements.</p>
                </div>
                
                <div class="info-card">
                    <h3>🔄 Dynamic Batching</h3>
                    <p>NVIDIA Triton's intelligent batching that combines requests from multiple streams. Significantly improves GPU utilization (2-5x throughput gains) but requires careful memory and latency planning.</p>
                </div>
                
                <div class="info-card">
                    <h3>💾 Result Storage</h3>
                    <p>Duration for storing inference results, logs, and metadata. Includes bounding boxes, confidence scores, tracking data, and alerts. Critical for compliance and system debugging.</p>
                </div>
            </div>
        </div>
        
        <div class="main-content">
            <div class="input-section">
                <form id="aiCalculatorForm">
                    <div class="form-group">
                        <label for="numStreams">Number of Video Streams</label>
                        <input type="number" id="numStreams" value="20" min="1" max="200">
                    </div>
                    
                    <div class="form-group">
                        <label for="modelsPerStream">AI Models per Stream</label>
                        <input type="number" id="modelsPerStream" value="3" min="1" max="10">
                    </div>
                    
                    <div class="form-group">
                        <label for="inferenceFps">Inference FPS</label>
                        <input type="number" id="inferenceFps" value="10" min="1" max="60">
                    </div>
                    
                    <div class="form-group">
                        <label for="inputResolution">Input Resolution</label>
                        <select id="inputResolution">
                            <option value="320p">320p (320x240)</option>
                            <option value="480p" selected>480p (640x480)</option>
                            <option value="720p">720p (1280x720)</option>
                        </select>
                    </div>
                    
                    <div class="form-group">
                        <label for="modelComplexity">Model Complexity</label>
                        <select id="modelComplexity">
                            <option value="lightweight">Lightweight (YOLOv5s, MobileNet)</option>
                            <option value="medium" selected>Medium (YOLOv8m, EfficientNet)</option>
                            <option value="heavy">Heavy (YOLOv8x, ResNet)</option>
                        </select>
                    </div>
                    
                    <div class="form-group">
                        <label for="batchSize">Batch Size</label>
                        <select id="batchSize">
                            <option value="1">1 (No Batching)</option>
                            <option value="4" selected>4 (Balanced)</option>
                            <option value="8">8 (High Throughput)</option>
                            <option value="16">16 (Maximum Throughput)</option>
                        </select>
                    </div>
                    
                    <div class="form-group">
                        <label for="dynamicBatching">Dynamic Batching (Triton)</label>
                        <select id="dynamicBatching">
                            <option value="enabled" selected>Enabled (Recommended)</option>
                            <option value="disabled">Disabled</option>
                        </select>
                    </div>
                    
                    <div class="form-group">
                        <label for="storageDays">Result Storage (Days)</label>
                        <input type="number" id="storageDays" value="30" min="1" max="365">
                    </div>
                    
                    <button type="submit" class="calculate-btn">Calculate AI Infrastructure</button>
                </form>
            </div>
            
            <div class="results-section">
                <div class="results-title">🚀 AI Infrastructure Requirements</div>
                <div id="results">
                    <div class="loading">
                        <div class="spinner"></div>
                        Configure your AI workload parameters and click "Calculate AI Infrastructure" to see the results
                    </div>
                </div>
            </div>
        </div>

        <!-- Technical Insights Section -->
        <div class="assumptions-info">
            <div class="section-title">⚙️ NVIDIA Triton Architecture & AI Calculations</div>
            <div class="section-subtitle">Understanding the computational model behind AI inference server planning</div>
            
            <div class="info-grid">
                <div class="info-card">
                    <h3>🎯 GPU Requirements</h3>
                    <p><strong>Memory-First Calculation:</strong> GPU VRAM determines maximum concurrent models and batch sizes. Each model requires base memory plus dynamic memory per batch. Modern GPUs: RTX 4090 (24GB), A100 (40GB), H100 (80GB).</p>
                </div>
                
                <div class="info-card">
                    <h3>💻 CPU & RAM</h3>
                    <p><strong>Preprocessing & Orchestration:</strong> CPUs handle video decode, preprocessing, and Triton orchestration. RAM requirements include frame buffers, model weights backup, and system overhead. Typically 4-8 CPU cores per GPU.</p>
                </div>
                
                <div class="info-card">
                    <h3>⚡ Inference Throughput</h3>
                    <p><strong>FPS × Models × Streams:</strong> Total inference operations per second. Dynamic batching can improve throughput by 2-5x but increases latency. Triton's scheduler optimizes batch formation automatically.</p>
                </div>
                
                <div class="info-card">
                    <h3>🧠 Model Memory</h3>
                    <p><strong>Base + Dynamic Allocation:</strong> Each model has fixed weights plus variable batch memory. YOLO models: 50-500MB, ResNet: 100-2GB. Memory sharing between models reduces total VRAM requirements.</p>
                </div>
                
                <div class="info-card">
                    <h3>🔄 Dynamic Batching</h3>
                    <p><strong>Triton's Key Feature:</strong> Automatically combines requests to maximize GPU utilization. Configurable max delay vs throughput trade-off. Essential for multi-stream scenarios with varying load patterns.</p>
                </div>
                
                <div class="info-card">
                    <h3>📊 Storage & Networking</h3>
                    <p><strong>Results & Metadata:</strong> Inference outputs (JSON), model artifacts, logs, and monitoring data. High-speed storage (NVMe SSD) recommended for model loading and result buffering.</p>
                </div>
            </div>

            <div class="key-metrics">
                <div class="metric-card">
                    <div class="metric-title">GPU Memory per Model</div>
                    <div class="metric-value">50MB - 2GB + Batch</div>
                </div>
                <div class="metric-card">
                    <div class="metric-title">CPU Cores per GPU</div>
                    <div class="metric-value">4-8 cores</div>
                </div>
                <div class="metric-card">
                    <div class="metric-title">Dynamic Batch Gain</div>
                    <div class="metric-value">2-5x throughput</div>
                </div>
                <div class="metric-card">
                    <div class="metric-title">Triton Overhead</div>
                    <div class="metric-value">10-15% resources</div>
                </div>
            </div>
        </div>
    </div>

    <script>
        // AI-specific calculation functions
        function resolutionToSize(resolution) {
            const resolutionMap = {
                "320p": [320, 240],
                "480p": [640, 480],
                "720p": [1280, 720],
            };
            return resolutionMap[resolution] || [640, 480];
        }

        function getModelMemoryRequirements(complexity) {
            // Base model memory in MB and compute units (relative)
            const modelSpecs = {
                "lightweight": { baseMB: 50, computeUnits: 1.0, batchMultiplier: 1.2 },
                "medium": { baseMB: 200, computeUnits: 2.5, batchMultiplier: 1.5 },
                "heavy": { baseMB: 800, computeUnits: 5.0, batchMultiplier: 2.0 }
            };
            return modelSpecs[complexity] || modelSpecs["medium"];
        }

        function calculateGPURequirements(streams, modelsPerStream, fps, resolution, complexity, batchSize, dynamicBatching) {
            const [width, height] = resolutionToSize(resolution);
            const modelSpec = getModelMemoryRequirements(complexity);
            
            // Frame size in MB (assume RGB, 3 bytes per pixel)
            const frameSizeMB = (width * height * 3) / (1024 * 1024);
            
            // Total models across all streams
            const totalModels = streams * modelsPerStream;
            
            // GPU Memory calculation
            const baseModelMemory = totalModels * modelSpec.baseMB;
            const batchMemoryPerModel = frameSizeMB * batchSize * modelSpec.batchMultiplier;
            const totalBatchMemory = totalModels * batchMemoryPerModel;
            
            // Dynamic batching efficiency
            const batchingEfficiency = dynamicBatching === 'enabled' ? 0.7 : 1.0; // 30% memory savings
            const effectiveMemory = (baseModelMemory + totalBatchMemory) * batchingEfficiency;
            
            // Add Triton overhead (15%)
            const tritonOverhead = effectiveMemory * 0.15;
            const totalGPUMemoryMB = effectiveMemory + tritonOverhead;
            
            // Compute requirements (inference operations per second)
            const totalInferenceOps = streams * modelsPerStream * fps;
            const computeRequirement = totalInferenceOps * modelSpec.computeUnits;
            
            // Dynamic batching throughput improvement
            const throughputMultiplier = dynamicBatching === 'enabled' ? 3.0 : 1.0;
            const effectiveComputeRequirement = computeRequirement / throughputMultiplier;
            
            return {
                totalGPUMemoryGB: Math.ceil(totalGPUMemoryMB / 1024),
                totalGPUMemoryMB: Math.round(totalGPUMemoryMB),
                baseModelMemoryMB: Math.round(baseModelMemory),
                batchMemoryMB: Math.round(totalBatchMemory),
                tritonOverheadMB: Math.round(tritonOverhead),
                computeRequirement: Math.round(effectiveComputeRequirement),
                totalInferenceOps: totalInferenceOps,
                frameSizeMB: Math.round(frameSizeMB * 100) / 100
            };
        }

        function recommendGPUs(memoryRequiredGB, computeRequirement) {
            const gpuOptions = [
                { name: "RTX 4060", memory: 8, compute: 100, price: "$300" },
                { name: "RTX 4070", memory: 12, compute: 150, price: "$600" },
                { name: "RTX 4080", memory: 16, compute: 200, price: "$1200" },
                { name: "RTX 4090", memory: 24, compute: 300, price: "$1600" },
                { name: "A40", memory: 48, compute: 250, price: "$4500" },
                { name: "A100", memory: 40, compute: 400, price: "$10000" },
                { name: "A100 80GB", memory: 80, compute: 400, price: "$15000" },
                { name: "H100", memory: 80, compute: 600, price: "$25000" }
            ];

            // Find suitable GPUs based on memory and compute requirements
            const suitableGPUs = gpuOptions.filter(gpu => 
                gpu.memory >= memoryRequiredGB && gpu.compute >= computeRequirement
            );

            if (suitableGPUs.length === 0) {
                const requiredGPUs = Math.ceil(memoryRequiredGB / 80); // Use H100 as baseline
                return `${requiredGPUs}x H100 (80GB each)`;
            }

            // Return the most cost-effective option
            return suitableGPUs[0].name;
        }

        function calculateCPUAndRAM(streams, gpuMemoryGB) {
            // CPU requirements: 4-8 cores per GPU, plus base system
            const estimatedGPUs = Math.max(1, Math.ceil(gpuMemoryGB / 24)); // Assume 24GB per GPU average
            const cpuCores = Math.max(8, estimatedGPUs * 6 + 4); // 6 cores per GPU + 4 base
            
            // RAM requirements: 2x GPU memory + system overhead
            const ramGB = Math.max(32, gpuMemoryGB * 2 + 16); // At least 32GB
            
            return { cpuCores, ramGB };
        }

        function calculateStorage(streams, modelsPerStream, fps, storageDays) {
            // Inference results storage (JSON outputs, logs, metadata)
            const resultsPerSecond = streams * modelsPerStream * fps;
            const avgResultSizeKB = 5; // JSON with bounding boxes, confidence scores
            const dailyResultsGB = (resultsPerSecond * avgResultSizeKB * 86400) / (1024 * 1024);
            
            // Model storage (weights, configs, versions)
            const modelStorageGB = modelsPerStream * 2; // Average 2GB per unique model
            
            // System logs and monitoring
            const systemLogsGB = storageDays * 0.5; // 500MB per day
            
            const totalStorageGB = Math.ceil(
                dailyResultsGB * storageDays + modelStorageGB + systemLogsGB
            );
            
            return {
                totalStorageGB,
                dailyResultsGB: Math.round(dailyResultsGB * 100) / 100,
                modelStorageGB,
                systemLogsGB: Math.round(systemLogsGB)
            };
        }

        function calculateNetworking(streams, resolution) {
            const [width, height] = resolutionToSize(resolution);
            const frameSizeMB = (width * height * 3) / (1024 * 1024);
            
            // Estimate compressed video bitrate (assume 80% compression)
            const estimatedBitrateMbps = (frameSizeMB * 8 * 10) * 0.2; // 10 FPS, 80% compression
            const totalIngestMbps = Math.round(streams * estimatedBitrateMbps);
            
            // API and result egress (much lower)
            const apiEgressMbps = Math.round(streams * 0.1); // 100 Kbps per stream for results
            
            const totalBandwidth = totalIngestMbps + apiEgressMbps;
            
            let recommendedNIC;
            if (totalBandwidth <= 1000) recommendedNIC = "1 Gbps NIC";
            else if (totalBandwidth <= 10000) recommendedNIC = "10 Gbps NIC";
            else recommendedNIC = "25+ Gbps NIC";
            
            return {
                totalIngestMbps,
                apiEgressMbps,
                totalBandwidth,
                recommendedNIC
            };
        }

        function estimateAIHardwareRequirements(params) {
            const {
                numStreams = 20,
                modelsPerStream = 3,
                inferenceFps = 10,
                inputResolution = '480p',
                modelComplexity = 'medium',
                batchSize = 4,
                dynamicBatching = 'enabled',
                storageDays = 30
            } = params;

            // Calculate GPU requirements
            const gpuReqs = calculateGPURequirements(
                numStreams, modelsPerStream, inferenceFps, 
                inputResolution, modelComplexity, parseInt(batchSize), dynamicBatching
            );

            // Calculate CPU and RAM
            const { cpuCores, ramGB } = calculateCPUAndRAM(numStreams, gpuReqs.totalGPUMemoryGB);

            // Calculate storage
            const storage = calculateStorage(numStreams, modelsPerStream, inferenceFps, storageDays);

            // Calculate networking
            const networking = calculateNetworking(numStreams, inputResolution);

            // Recommend GPUs
            const recommendedGPU = recommendGPUs(gpuReqs.totalGPUMemoryGB, gpuReqs.computeRequirement);

            return {
                "Recommended GPU Configuration": recommendedGPU,
                "Total GPU Memory Required (GB)": gpuReqs.totalGPUMemoryGB,
                "Estimated CPU Cores": cpuCores,
                "Estimated RAM (GB)": ramGB,
                [`Total Storage for ${storageDays} Days (GB)`]: storage.totalStorageGB,
                "Total Inference Operations/sec": gpuReqs.totalInferenceOps,
                "Video Ingest Bandwidth (Mbps)": networking.totalIngestMbps,
                "API Egress Bandwidth (Mbps)": networking.apiEgressMbps,
                "Recommended Network Interface": networking.recommendedNIC,
                "Assumptions": {
                    "Streams": numStreams,
                    "Models per Stream": modelsPerStream,
                    "Inference FPS": inferenceFps,
                    "Input Resolution": inputResolution,
                    "Model Complexity": modelComplexity,
                    "Batch Size": batchSize,
                    "Dynamic Batching": dynamicBatching,
                    "Frame Size (MB)": gpuReqs.frameSizeMB,
                    "Base Model Memory (MB)": gpuReqs.baseModelMemoryMB,
                    "Batch Memory (MB)": gpuReqs.batchMemoryMB,
                    "Triton Overhead (MB)": gpuReqs.tritonOverheadMB,
                    "Daily Results Storage (GB)": storage.dailyResultsGB,
                    "Model Storage (GB)": storage.modelStorageGB,
                    "Batching Efficiency": dynamicBatching === 'enabled' ? "30% memory savings" : "No optimization",
                    "Throughput Multiplier": dynamicBatching === 'enabled' ? "3x improvement" : "1x baseline"
                }
            };
        }

        function displayResults(results) {
            const resultsDiv = document.getElementById('results');
            
            // Main results
            const mainResults = Object.entries(results).filter(([key]) => key !== 'Assumptions');
            const assumptions = results.Assumptions;
            
            let html = '';
            
            // Main requirements card
            html += '<div class="result-card">';
            mainResults.forEach(([key, value]) => {
                const isHighlight = key.includes('GPU') || key.includes('CPU') || key.includes('RAM');
                html += `
                    <div class="result-item">
                        <span class="result-label">${key}</span>
                        <span class="result-value ${isHighlight ? 'highlight-value' : ''}">${typeof value === 'number' ? value.toLocaleString() : value}</span>
                    </div>
                `;
            });
            html += '</div>';
            
            // Assumptions section
            html += '<div class="assumptions-section">';
            html += '<div class="assumptions-title">🔧 Configuration & Calculations</div>';
            Object.entries(assumptions).forEach(([key, value]) => {
                html += `
                    <div class="result-item">
                        <span class="result-label">${key}</span>
                        <span class="result-value">${typeof value === 'number' ? value.toLocaleString() : value}</span>
                    </div>
                `;
            });
            html += '</div>';
            
            resultsDiv.innerHTML = html;
            
            // Animate results
            setTimeout(() => {
                document.querySelectorAll('.result-card, .assumptions-section').forEach((card, index) => {
                    setTimeout(() => {
                        card.classList.add('show');
                    }, index * 200);
                });
            }, 100);
        }

        // Form submission
        document.getElementById('aiCalculatorForm').addEventListener('submit', function(e) {
            e.preventDefault();
            
            const params = {
                numStreams: parseInt(document.getElementById('numStreams').value),
                modelsPerStream: parseInt(document.getElementById('modelsPerStream').value),
                inferenceFps: parseInt(document.getElementById('inferenceFps').value),
                inputResolution: document.getElementById('inputResolution').value,
                modelComplexity: document.getElementById('modelComplexity').value,
                batchSize: document.getElementById('batchSize').value,
                dynamicBatching: document.getElementById('dynamicBatching').value,
                storageDays: parseInt(document.getElementById('storageDays').value)
            };
            
            const results = estimateAIHardwareRequirements(params);
            displayResults(results);
        });

        // Calculate initial results
        window.addEventListener('load', function() {
            setTimeout(() => {
                document.getElementById('aiCalculatorForm').dispatchEvent(new Event('submit'));
            }, 1000);
        });

        // Real-time calculation on input change
        document.querySelectorAll('input, select').forEach(input => {
            input.addEventListener('input', function() {
                // Debounce the calculation
                clearTimeout(window.calcTimeout);
                window.calcTimeout = setTimeout(() => {
                    document.getElementById('aiCalculatorForm').dispatchEvent(new Event('submit'));
                }, 500);
            });
        });
    </script>
</body>
</html>
